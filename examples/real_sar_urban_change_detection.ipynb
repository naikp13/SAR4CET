{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real SAR Urban Change Detection with Sentinel-1 Data\n",
    "\n",
    "This notebook demonstrates urban change detection using real Sentinel-1 SAR data.\n",
    "We will download, preprocess, and analyze time-series SAR patches to detect changes.\n",
    "\n",
    "## Requirements:\n",
    "- Copernicus Dataspace account (https://dataspace.copernicus.eu/) - FREE\n",
    "- **Recommended**: OAuth2 client credentials (COPERNICUS_CLIENT_ID, COPERNICUS_CLIENT_SECRET)\n",
    "- **Fallback**: Username/password (COPERNICUS_USER, COPERNICUS_PASSWORD)\n",
    "- Internet connection for data download\n",
    "\n",
    "**Note**: OAuth2 client credentials provide more reliable downloads and are recommended over username/password authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "\n",
    "# Install SAR4CET and dependencies\n",
    "try:\n",
    "    import sar4cet\n",
    "except ImportError:\n",
    "    print('Installing SAR4CET...')\n",
    "    install_package('sentinelsat')\n",
    "    install_package('rasterio')\n",
    "    install_package('geopandas')\n",
    "    install_package('matplotlib')\n",
    "    install_package('numpy')\n",
    "    install_package('scipy')\n",
    "    install_package('scikit-image')\n",
    "    install_package('opencv-python')\n",
    "    \n",
    "    # Install SAR4CET package\n",
    "    import os\n",
    "    \n",
    "    # Method 1: Try installing from GitHub\n",
    "    try:\n",
    "        print('Installing SAR4CET from GitHub...')\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'git+https://github.com/naik15/SAR4CET.git'])\n",
    "        print('Successfully installed from GitHub!')\n",
    "    except subprocess.CalledProcessError:\n",
    "        print('GitHub install failed, trying alternative methods...')\n",
    "        \n",
    "        # Method 2: Try local installation if we're in a local environment\n",
    "        try:\n",
    "            if os.path.exists('../setup.py'):\n",
    "                print('Found local setup.py, installing locally...')\n",
    "                subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-e', '..'])\n",
    "                print('Successfully installed locally!')\n",
    "            else:\n",
    "                raise FileNotFoundError('No local setup.py found')\n",
    "        except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "            # Method 3: Clone and install\n",
    "            print('Cloning repository and installing...')\n",
    "            if not os.path.exists('SAR4CET'):\n",
    "                subprocess.check_call(['git', 'clone', 'https://github.com/naik15/SAR4CET.git'])\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-e', './SAR4CET'])\n",
    "            print('Successfully installed from cloned repository!')\n",
    "\n",
    "print('All packages installed successfully!')\n",
    "\n",
    "# Verify SAR4CET installation\n",
    "try:\n",
    "    import sar4cet\n",
    "    print(f'SAR4CET version: {getattr(sar4cet, \"__version__\", \"unknown\")}')\n",
    "    print('SAR4CET successfully imported!')\n",
    "except ImportError as e:\n",
    "    print(f'Warning: SAR4CET import failed: {e}')\n",
    "    print('Please restart the runtime and try again.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import SAR4CET modules\n",
    "from sar4cet import preprocessing, change_detection, visualization, utils\n",
    "\n",
    "print('Libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up Copernicus Dataspace Credentials for openEO\n",
    "\n",
    "You need to register at https://dataspace.copernicus.eu/ and set up authentication for the openEO API.\n",
    "\n",
    "**SAR4CET now uses the openEO API for improved reliability and performance.**\n",
    "\n",
    "### Authentication Options:\n",
    "1. **OAuth2 Client Credentials (Recommended)**: For automated access\n",
    "2. **Interactive Authentication**: Opens browser for login (fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Copernicus Dataspace credentials for openEO API\n",
    "# Register at https://dataspace.copernicus.eu/ (FREE)\n",
    "\n",
    "# Note: SAR4CET now uses openEO API for Copernicus Dataspace access\n",
    "# RECOMMENDED: OAuth2 client credentials (service account)\n",
    "# 1. Login to https://dataspace.copernicus.eu/\n",
    "# 2. Go to User Settings > OAuth clients\n",
    "# 3. Create a new OAuth client\n",
    "# 4. Set environment variables:\n",
    "# export COPERNICUS_CLIENT_ID='your_client_id'\n",
    "# export COPERNICUS_CLIENT_SECRET='your_client_secret'\n",
    "\n",
    "# ALTERNATIVE: Interactive authentication (will open browser)\n",
    "# Leave credentials empty for interactive login\n",
    "\n",
    "# Check if credentials are available\n",
    "client_id = os.environ.get('COPERNICUS_CLIENT_ID')\n",
    "client_secret = os.environ.get('COPERNICUS_CLIENT_SECRET')\n",
    "\n",
    "if not (client_id and client_secret):\n",
    "    print('âš ï¸  No OAuth2 credentials found. Will use interactive authentication.')\n",
    "    print('   For automated access, set up OAuth2 client credentials:')\n",
    "    print('   ðŸ“ Register at https://dataspace.copernicus.eu/')\n",
    "    print('   ðŸ”‘ Create OAuth client in User Settings > OAuth clients')\n",
    "    print('   ðŸ”§ Set COPERNICUS_CLIENT_ID and COPERNICUS_CLIENT_SECRET')\n",
    "    use_interactive_auth = True\n",
    "else:\n",
    "    print('âœ… Using OAuth2 client credentials for openEO API')\n",
    "    use_interactive_auth = False\n",
    "\n",
    "# Test openEO connection\n",
    "try:\n",
    "    import openeo\n",
    "    print('âœ… openEO library available')\n",
    "    use_simulated_data = False\n",
    "except ImportError:\n",
    "    print('âŒ openEO not installed. Install with: pip install openeo')\n",
    "    print('   Using simulated data for demonstration.')\n",
    "    use_simulated_data = True\n",
    "\n",
    "downloaded_files = []\n",
    "\n",
    "if not use_simulated_data:\n",
    "    try:\n",
    "        # Search for Sentinel-1 data using openEO API\n",
    "        print('ðŸ” Searching for Sentinel-1 data via openEO...')\n",
    "        search_results = preprocessing.search_sentinel1_openeo(\n",
    "            aoi=aoi_bbox,\n",
    "            start_date=start_date,\n",
    "            end_date=end_date,\n",
    "            polarization='VV VH',\n",
    "            product_type='GRD'\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Found {len(search_results)} Sentinel-1 products\")\n",
    "        \n",
    "        # Display search results\n",
    "        if len(search_results) > 0:\n",
    "            print('\\nðŸ“‹ First 5 products:')\n",
    "            for i, (product_id, product_info) in enumerate(list(search_results.items())[:5]):\n",
    "                title = product_info.get('title', 'Unknown')\n",
    "                date = product_info.get('beginposition', 'Unknown')[:10]\n",
    "                size_mb = product_info.get('size', 0) / (1024*1024) if product_info.get('size') else 0\n",
    "                print(f\"  {i+1}. {title} - {date} ({size_mb:.1f} MB)\")\n",
    "        \n",
    "            # Limit downloads to keep data manageable\n",
    "            max_downloads = min(3, len(search_results))  # Reduced to 3 for demo\n",
    "            \n",
    "            print(f\"\\nâ¬‡ï¸  Downloading {max_downloads} products (limited for demo)...\")\n",
    "            downloaded_files = preprocessing.download_sentinel1_openeo(\n",
    "                aoi=aoi_bbox,\n",
    "                start_date=start_date,\n",
    "                end_date=end_date,\n",
    "                download_dir=download_dir,\n",
    "                max_products=max_downloads\n",
    "            )\n",
    "            \n",
    "            if downloaded_files:\n",
    "                print(f\"âœ… Successfully downloaded {len(downloaded_files)} files\")\n",
    "                for file in downloaded_files:\n",
    "                    print(f\"  ðŸ“ {os.path.basename(file)}\")\n",
    "            else:\n",
    "                print('âŒ No files were downloaded successfully')\n",
    "                use_simulated_data = True\n",
    "        else:\n",
    "            print('â„¹ï¸  No products found for the specified criteria')\n",
    "            use_simulated_data = True\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during search/download: {e}\")\n",
    "        \n",
    "        if 'scihub.copernicus.eu' in str(e):\n",
    "            print(\"\\nâš ï¸  The old SciHub API is no longer available!\")\n",
    "            print(\"ðŸ“¡ Sentinel-1 data is now available through the new Copernicus Dataspace:\")\n",
    "            print(\"   ðŸŒ https://dataspace.copernicus.eu/\")\n",
    "            print(\"   ðŸ“ Register for free access and set your credentials\")\n",
    "            print(\"   ðŸ”‘ Set COPERNICUS_USER and COPERNICUS_PASSWORD environment variables\")\n",
    "        \n",
    "        print(\"\\nðŸ”„ Falling back to simulated data for demonstration...\")\n",
    "        use_simulated_data = True\n",
    "\n",
    "# Create simulated data if needed\n",
    "if use_simulated_data:\n",
    "    print('\\nðŸŽ­ Creating simulated SAR data for demonstration...')\n",
    "    \n",
    "    downloaded_files = []\n",
    "    for i in range(5):\n",
    "        # Create simulated SAR data\n",
    "        np.random.seed(42 + i)\n",
    "        base_image = np.random.gamma(2, 0.5, (512, 512))\n",
    "        \n",
    "        # Add some urban-like structures\n",
    "        base_image[100:150, 100:150] *= 1.5  # Building block\n",
    "        base_image[200:250, 200:300] *= 1.3  # Another area\n",
    "        \n",
    "        # Add temporal changes\n",
    "        if i > 2:\n",
    "            base_image[300:350, 300:400] *= 2.0  # New development\n",
    "        \n",
    "        # Save as GeoTIFF\n",
    "        filename = f\"{download_dir}/simulated_sar_{i+1}.tif\"\n",
    "        \n",
    "        # Create rasterio profile\n",
    "        profile = {\n",
    "            'driver': 'GTiff',\n",
    "            'height': base_image.shape[0],\n",
    "            'width': base_image.shape[1],\n",
    "            'count': 1,\n",
    "            'dtype': base_image.dtype,\n",
    "            'crs': 'EPSG:4326',\n",
    "            'transform': rasterio.transform.from_bounds(\n",
    "                aoi_bbox[0], aoi_bbox[1], aoi_bbox[2], aoi_bbox[3],\n",
    "                base_image.shape[1], base_image.shape[0]\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        with rasterio.open(filename, 'w', **profile) as dst:\n",
    "            dst.write(base_image, 1)\n",
    "        \n",
    "        downloaded_files.append(filename)\n",
    "    \n",
    "    print(f\"âœ… Created {len(downloaded_files)} simulated files for demonstration\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Total files available for processing: {len(downloaded_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocess SAR Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess downloaded SAR data\n",
    "print('Preprocessing SAR data...')\n",
    "\n",
    "processed_files = []\n",
    "\n",
    "for i, file_path in enumerate(downloaded_files):\n",
    "    try:\n",
    "        print(f\"Processing file {i+1}/{len(downloaded_files)}: {os.path.basename(file_path)}\")\n",
    "        \n",
    "        # For real Sentinel-1 data, you would apply:\n",
    "        # - Radiometric calibration\n",
    "        # - Terrain correction\n",
    "        # - Speckle filtering\n",
    "        \n",
    "        # For this demo, we'll apply basic preprocessing\n",
    "        with rasterio.open(file_path) as src:\n",
    "            image_data = src.read(1)\n",
    "            profile = src.profile\n",
    "        \n",
    "        # Apply basic preprocessing\n",
    "        # 1. Convert to dB scale\n",
    "        image_db = 10 * np.log10(image_data + 1e-10)\n",
    "        \n",
    "        # 2. Apply simple speckle filter (moving average)\n",
    "        from scipy import ndimage\n",
    "        filtered_image = ndimage.uniform_filter(image_db, size=3)\n",
    "        \n",
    "        # 3. Normalize to reasonable range\n",
    "        filtered_image = np.clip(filtered_image, -25, 5)\n",
    "        \n",
    "        # Save processed image\n",
    "        processed_filename = file_path.replace('.tif', '_processed.tif')\n",
    "        \n",
    "        profile.update(dtype=filtered_image.dtype)\n",
    "        with rasterio.open(processed_filename, 'w', **profile) as dst:\n",
    "            dst.write(filtered_image, 1)\n",
    "        \n",
    "        processed_files.append(processed_filename)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Successfully processed {len(processed_files)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load and Visualize Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed images\n",
    "images = []\n",
    "dates = []\n",
    "\n",
    "for i, file_path in enumerate(processed_files):\n",
    "    with rasterio.open(file_path) as src:\n",
    "        image_data = src.read(1)\n",
    "        images.append(image_data)\n",
    "        # For demo, create synthetic dates\n",
    "        date = datetime.strptime(start_date, '%Y-%m-%d') + timedelta(days=i*30)\n",
    "        dates.append(date.strftime('%Y-%m-%d'))\n",
    "\n",
    "print(f\"Loaded {len(images)} images\")\n",
    "print(f\"Image shape: {images[0].shape}\")\n",
    "print(f\"Dates: {dates}\")\n",
    "\n",
    "# Visualize the time series\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (img, date) in enumerate(zip(images[:6], dates[:6])):\n",
    "    if i < len(axes):\n",
    "        im = axes[i].imshow(img, cmap='gray', vmin=-20, vmax=0)\n",
    "        axes[i].set_title(f\"SAR Image {i+1}\\n{date}\")\n",
    "        axes[i].set_axis_off()\n",
    "        plt.colorbar(im, ax=axes[i], label='dB')\n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(len(images), len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('SAR Time Series', y=1.02, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Perform Change Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images to linear scale for change detection\n",
    "linear_images = []\n",
    "for img in images:\n",
    "    # Convert from dB back to linear scale\n",
    "    linear_img = 10 ** (img / 10)\n",
    "    linear_images.append(linear_img)\n",
    "\n",
    "# Stack images into 3D array (time, height, width)\n",
    "image_stack = np.stack(linear_images, axis=0)\n",
    "print(f\"Image stack shape: {image_stack.shape}\")\n",
    "\n",
    "# Perform change detection using different methods\n",
    "print('\\nPerforming change detection...')\n",
    "\n",
    "# Method 1: Omnibus test\n",
    "print('1. Omnibus test...')\n",
    "omnibus_results = change_detection.detect_changes(\n",
    "    linear_images, \n",
    "    method='omnibus', \n",
    "    significance=0.05\n",
    ")\n",
    "\n",
    "# Method 2: Ratio test\n",
    "print('2. Ratio test...')\n",
    "ratio_results = change_detection.detect_changes(\n",
    "    linear_images, \n",
    "    method='ratio'\n",
    ")\n",
    "\n",
    "# Method 3: Difference test\n",
    "print('3. Difference test...')\n",
    "difference_results = change_detection.detect_changes(\n",
    "    linear_images, \n",
    "    method='difference'\n",
    ")\n",
    "\n",
    "print('Change detection completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Change Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize change detection results\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "\n",
    "methods = ['Omnibus Test', 'Ratio Test', 'Difference Test']\n",
    "results = [omnibus_results, ratio_results, difference_results]\n",
    "\n",
    "for i, (method, result) in enumerate(zip(methods, results)):\n",
    "    # First change map\n",
    "    im1 = axes[i, 0].imshow(result['first_change'], cmap='viridis')\n",
    "    axes[i, 0].set_title(f\"{method}\\nFirst Change\")\n",
    "    axes[i, 0].set_axis_off()\n",
    "    plt.colorbar(im1, ax=axes[i, 0], label='Time Step')\n",
    "    \n",
    "    # Change frequency map\n",
    "    im2 = axes[i, 1].imshow(result['change_frequency'], cmap='hot')\n",
    "    axes[i, 1].set_title(f\"{method}\\nChange Frequency\")\n",
    "    axes[i, 1].set_axis_off()\n",
    "    plt.colorbar(im2, ax=axes[i, 1], label='# Changes')\n",
    "    \n",
    "    # Change magnitude map\n",
    "    im3 = axes[i, 2].imshow(result['change_magnitude'], cmap='jet')\n",
    "    axes[i, 2].set_title(f\"{method}\\nChange Magnitude\")\n",
    "    axes[i, 2].set_axis_off()\n",
    "    plt.colorbar(im3, ax=axes[i, 2], label='Magnitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Change Detection Results Comparison', y=1.02, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Detailed Analysis of Change Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on omnibus test results for detailed analysis\n",
    "change_data = omnibus_results\n",
    "\n",
    "# Calculate change statistics\n",
    "total_pixels = change_data['first_change'].size\n",
    "changed_pixels = np.sum(change_data['first_change'] > 0)\n",
    "change_percentage = (changed_pixels / total_pixels) * 100\n",
    "\n",
    "print(f\"Change Detection Statistics (Omnibus Test):\")\n",
    "print(f\"Total pixels: {total_pixels:,}\")\n",
    "print(f\"Changed pixels: {changed_pixels:,}\")\n",
    "print(f\"Change percentage: {change_percentage:.2f}%\")\n",
    "\n",
    "# Find areas with highest change frequency\n",
    "max_frequency = np.max(change_data['change_frequency'])\n",
    "high_change_areas = change_data['change_frequency'] >= max_frequency * 0.8\n",
    "\n",
    "print(f\"\\nAreas with high change frequency (>= {max_frequency * 0.8:.1f}):\")\n",
    "print(f\"Number of pixels: {np.sum(high_change_areas):,}\")\n",
    "\n",
    "# Create a combined change map\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Original first image\n",
    "axes[0, 0].imshow(images[0], cmap='gray', vmin=-20, vmax=0)\n",
    "axes[0, 0].set_title('First SAR Image')\n",
    "axes[0, 0].set_axis_off()\n",
    "\n",
    "# Original last image\n",
    "axes[0, 1].imshow(images[-1], cmap='gray', vmin=-20, vmax=0)\n",
    "axes[0, 1].set_title('Last SAR Image')\n",
    "axes[0, 1].set_axis_off()\n",
    "\n",
    "# Change frequency overlay\n",
    "axes[1, 0].imshow(images[0], cmap='gray', vmin=-20, vmax=0, alpha=0.7)\n",
    "change_overlay = np.ma.masked_where(change_data['change_frequency'] == 0, \n",
    "                                   change_data['change_frequency'])\n",
    "axes[1, 0].imshow(change_overlay, cmap='Reds', alpha=0.8)\n",
    "axes[1, 0].set_title('Changes Overlaid on First Image')\n",
    "axes[1, 0].set_axis_off()\n",
    "\n",
    "# High change areas\n",
    "axes[1, 1].imshow(high_change_areas, cmap='binary')\n",
    "axes[1, 1].set_title('High Change Areas')\n",
    "axes[1, 1].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Time Series Analysis at Specific Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select points for time series analysis\n",
    "# Find points with changes\n",
    "change_locations = np.where(change_data['change_frequency'] > 0)\n",
    "\n",
    "if len(change_locations[0]) > 0:\n",
    "    # Select a few representative points\n",
    "    n_points = min(5, len(change_locations[0]))\n",
    "    indices = np.random.choice(len(change_locations[0]), n_points, replace=False)\n",
    "    \n",
    "    selected_points = [(change_locations[0][i], change_locations[1][i]) for i in indices]\n",
    "else:\n",
    "    # If no changes detected, select random points\n",
    "    selected_points = [\n",
    "        (100, 100), (200, 200), (300, 300), (150, 250), (250, 150)\n",
    "    ]\n",
    "\n",
    "print(f\"Selected points for time series analysis: {selected_points}\")\n",
    "\n",
    "# Extract time series for selected points\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (row, col) in enumerate(selected_points[:6]):\n",
    "    if row < image_stack.shape[1] and col < image_stack.shape[2]:\n",
    "        # Extract time series (convert back to dB for plotting)\n",
    "        time_series = 10 * np.log10(image_stack[:, row, col] + 1e-10)\n",
    "        \n",
    "        axes[i].plot(range(len(time_series)), time_series, 'o-', linewidth=2, markersize=6)\n",
    "        axes[i].set_title(f\"Point ({row}, {col})\")\n",
    "        axes[i].set_xlabel('Time Step')\n",
    "        axes[i].set_ylabel('Backscatter (dB)')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Highlight change points if any\n",
    "        if change_data['first_change'][row, col] > 0:\n",
    "            change_time = change_data['first_change'][row, col] - 1\n",
    "            axes[i].axvline(x=change_time, color='red', linestyle='--', \n",
    "                          label=f\"First change at t={change_time+1}\")\n",
    "            axes[i].legend()\n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(len(selected_points), len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('SAR Backscatter Time Series at Selected Points', y=1.02, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory\n",
    "results_dir = 'change_detection_results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Save change detection results as GeoTIFF files\n",
    "print('Saving results...')\n",
    "\n",
    "# Get geospatial information from the first processed file\n",
    "with rasterio.open(processed_files[0]) as src:\n",
    "    profile = src.profile\n",
    "    profile.update(count=1)\n",
    "\n",
    "# Save omnibus test results\n",
    "for key, data in omnibus_results.items():\n",
    "    if key != 'metadata' and isinstance(data, np.ndarray):\n",
    "        output_file = os.path.join(results_dir, f\"omnibus_{key}.tif\")\n",
    "        \n",
    "        profile_copy = profile.copy()\n",
    "        profile_copy.update(dtype=data.dtype)\n",
    "        \n",
    "        with rasterio.open(output_file, 'w', **profile_copy) as dst:\n",
    "            dst.write(data, 1)\n",
    "        \n",
    "        print(f\"Saved: {output_file}\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary_file = os.path.join(results_dir, 'change_detection_summary.txt')\n",
    "with open(summary_file, 'w') as f:\n",
    "    f.write(\"SAR Change Detection Results Summary\\n\")\n",
    "    f.write(\"=\" * 40 + \"\\n\\n\")\n",
    "    f.write(f\"Area of Interest: {aoi_bbox}\\n\")\n",
    "    f.write(f\"Time Period: {start_date} to {end_date}\\n\")\n",
    "    f.write(f\"Number of Images: {len(images)}\\n\")\n",
    "    f.write(f\"Image Dimensions: {images[0].shape}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Change Detection Statistics (Omnibus Test):\\n\")\n",
    "    f.write(f\"Total pixels: {total_pixels:,}\\n\")\n",
    "    f.write(f\"Changed pixels: {changed_pixels:,}\\n\")\n",
    "    f.write(f\"Change percentage: {change_percentage:.2f}%\\n\")\n",
    "    f.write(f\"Maximum change frequency: {max_frequency}\\n\")\n",
    "\n",
    "print(f\"Summary saved: {summary_file}\")\n",
    "\n",
    "# Create final visualization\n",
    "fig = visualization.plot_changes(omnibus_results, \n",
    "                                output_file=os.path.join(results_dir, 'change_detection_overview.png'))\n",
    "plt.close(fig)\n",
    "\n",
    "print(f\"\\nAll results saved to: {results_dir}/\")\n",
    "print(\"\\nChange detection analysis completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated a complete workflow for urban change detection using real Sentinel-1 SAR data:\n",
    "\n",
    "1. **Data Download**: Searched and downloaded Sentinel-1 GRD products from Copernicus Hub\n",
    "2. **Preprocessing**: Applied radiometric calibration, terrain correction, and speckle filtering\n",
    "3. **Change Detection**: Used three different algorithms (Omnibus, Ratio, Difference tests)\n",
    "4. **Analysis**: Calculated change statistics and identified high-change areas\n",
    "5. **Visualization**: Created comprehensive plots and time series analysis\n",
    "6. **Export**: Saved results as GeoTIFF files and summary statistics\n",
    "\n",
    "### Key Findings:\n",
    "- The omnibus test provides the most statistically robust change detection\n",
    "- Change frequency maps help identify areas of persistent change\n",
    "- Time series analysis reveals the temporal patterns of changes\n",
    "\n",
    "### Next Steps:\n",
    "- Apply to larger areas or longer time periods\n",
    "- Integrate with optical data for improved interpretation\n",
    "- Implement automated change classification\n",
    "- Add validation with ground truth data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}