{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flood Impact Assessment in Emilia Romagna using Sentinel-1 SAR Data\n",
    "\n",
    "This notebook demonstrates flood impact assessment in Emilia Romagna, Italy using Sentinel-1 SAR data accessed through the openEO API. The analysis focuses on the severe flooding events that occurred around May 16-17, 2023.\n",
    "\n",
    "## Background\n",
    "In May 2023, Emilia Romagna experienced severe flooding due to intense rainfall, affecting thousands of people and causing significant damage to infrastructure and agriculture. SAR data is particularly valuable for flood monitoring because:\n",
    "\n",
    "- **Weather Independence**: SAR can penetrate clouds and operate day/night\n",
    "- **Water Detection**: Water appears dark in SAR images due to specular reflection\n",
    "- **Change Detection**: Comparing pre- and post-flood images reveals flooded areas\n",
    "\n",
    "## Requirements\n",
    "- SAR4CET toolkit (will be installed below)\n",
    "- openEO Python client\n",
    "- Copernicus Dataspace account for authentication\n",
    "- xarray, matplotlib, numpy for data processing and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup and Installation\n",
    "\n",
    "First, let's clone the SAR4CET repository and install all required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the SAR4CET repository\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Check if SAR4CET directory already exists\n",
    "if not os.path.exists('SAR4CET'):\n",
    "    print('Cloning SAR4CET repository...')\n",
    "    result = subprocess.run(['git', 'clone', 'https://github.com/naikp13/SAR4CET.git'], \n",
    "                          capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print('Repository cloned successfully!')\n",
    "    else:\n",
    "        print(f'Error cloning repository: {result.stderr}')\n",
    "else:\n",
    "    print('SAR4CET directory already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements from requirements.txt\n",
    "print('Installing SAR4CET requirements...')\n",
    "\n",
    "# Change to SAR4CET directory and install requirements\n",
    "if os.path.exists('SAR4CET/requirements.txt'):\n",
    "    result = subprocess.run([sys.executable, '-m', 'pip', 'install', '-r', 'SAR4CET/requirements.txt'], \n",
    "                          capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print('Requirements installed successfully!')\n",
    "        print('Installed packages from requirements.txt')\n",
    "    else:\n",
    "        print(f'Error installing requirements: {result.stderr}')\n",
    "        print('Trying to install individual packages...')\n",
    "        # Try installing key packages individually\n",
    "        key_packages = ['openeo>=0.22.0', 'xarray>=0.19.0', 'numpy>=1.20.0', \n",
    "                       'matplotlib>=3.4.0', 'rasterio>=1.2.0', 'scipy>=1.7.0']\n",
    "        for package in key_packages:\n",
    "            subprocess.run([sys.executable, '-m', 'pip', 'install', package])\n",
    "else:\n",
    "    print('requirements.txt not found, installing key packages manually...')\n",
    "    key_packages = ['openeo>=0.22.0', 'xarray>=0.19.0', 'numpy>=1.20.0', \n",
    "                   'matplotlib>=3.4.0', 'rasterio>=1.2.0', 'scipy>=1.7.0']\n",
    "    for package in key_packages:\n",
    "        subprocess.run([sys.executable, '-m', 'pip', 'install', package])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add SAR4CET to Python path for imports\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add SAR4CET directory to Python path\n",
    "sar4cet_path = os.path.abspath('SAR4CET')\n",
    "if sar4cet_path not in sys.path:\n",
    "    sys.path.insert(0, sar4cet_path)\n",
    "    print(f'Added {sar4cet_path} to Python path')\n",
    "\n",
    "# Verify installation by importing key modules\n",
    "try:\n",
    "    import openeo\n",
    "    import xarray as xr\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from scipy import ndimage\n",
    "    print('All required packages imported successfully!')\n",
    "    print(f'openEO version: {openeo.__version__}')\n",
    "    print(f'xarray version: {xr.__version__}')\n",
    "except ImportError as e:\n",
    "    print(f'Import error: {e}')\n",
    "    print('Please install missing packages manually.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "Now let's import all the libraries we'll need for the flood impact analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "from scipy.stats import zscore\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set matplotlib parameters for better plots\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Optional: Import SAR4CET modules if available\n",
    "try:\n",
    "    from sar4cet import preprocessing, visualization\n",
    "    print('SAR4CET modules imported successfully!')\n",
    "except ImportError:\n",
    "    print('SAR4CET modules not available, using standalone approach.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect to openEO Backend\n",
    "\n",
    "Connect to the Copernicus Dataspace openEO backend and authenticate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Copernicus Dataspace openEO backend\n",
    "backend = 'openeo.dataspace.copernicus.eu'\n",
    "conn = openeo.connect(backend).authenticate_oidc()\n",
    "print(f'Connected to {backend}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Area of Interest and Time Periods\n",
    "\n",
    "We'll focus on the area around Ravenna and Faenza in Emilia Romagna, which were severely affected by the May 2023 floods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area of Interest: Emilia Romagna flood-affected region\n",
    "# Centered around Ravenna-Faenza area (44.3640607, 12.0590095)\n",
    "spatial_extent = {\n",
    "    'west': 11.8000,   # Western boundary\n",
    "    'east': 12.3000,   # Eastern boundary\n",
    "    'south': 44.1000,  # Southern boundary\n",
    "    'north': 44.6000,  # Northern boundary\n",
    "    'crs': 'EPSG:4326',\n",
    "}\n",
    "\n",
    "# Define time periods for flood analysis\n",
    "# Pre-flood period (stable conditions)\n",
    "pre_flood_period = ['2023-05-01', '2023-05-15']\n",
    "\n",
    "# Post-flood period (during and after flooding)\n",
    "post_flood_period = ['2023-05-17', '2023-05-31']\n",
    "\n",
    "# Reference period for comparison (same time previous year)\n",
    "reference_period = ['2022-05-01', '2022-05-31']\n",
    "\n",
    "print(f'Area of Interest: {spatial_extent}')\n",
    "print(f'Pre-flood period: {pre_flood_period[0]} to {pre_flood_period[1]}')\n",
    "print(f'Post-flood period: {post_flood_period[0]} to {post_flood_period[1]}')\n",
    "print(f'Reference period: {reference_period[0]} to {reference_period[1]}')\n",
    "\n",
    "# Calculate area coverage\n",
    "lat_range = spatial_extent['north'] - spatial_extent['south']\n",
    "lon_range = spatial_extent['east'] - spatial_extent['west']\n",
    "print(f'\\nArea coverage: {lat_range:.2f}° × {lon_range:.2f}° (~{lat_range*111:.0f} × {lon_range*85:.0f} km)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Process Sentinel-1 Data\n",
    "\n",
    "Load Sentinel-1 data for pre-flood, post-flood, and reference periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and process SAR data for a given time period\n",
    "def load_and_process_sar_flood(conn, spatial_extent, temporal_extent, period_name):\n",
    "    '''Load and process SAR data for flood analysis'''\n",
    "    print(f'Processing {period_name}: {temporal_extent[0]} to {temporal_extent[1]}')\n",
    "    \n",
    "    # Load Sentinel-1 data\n",
    "    s1 = conn.load_collection(\n",
    "        'SENTINEL1_GRD',\n",
    "        spatial_extent=spatial_extent,\n",
    "        bands=['VV', 'VH'],\n",
    "        temporal_extent=temporal_extent,\n",
    "        properties={'sat:orbit_state': lambda od: od == 'ASCENDING'},\n",
    "    )\n",
    "    \n",
    "    # Apply SAR backscatter processing\n",
    "    s1_scatter = s1.sar_backscatter(\n",
    "        coefficient='sigma0-ellipsoid', \n",
    "        elevation_model='COPERNICUS_30'\n",
    "    )\n",
    "    \n",
    "    # Convert to dB scale\n",
    "    s1bs = s1_scatter.apply(lambda x: 10 * x.log(base=10))\n",
    "    \n",
    "    # Create median composite to reduce speckle\n",
    "    s1_median = s1bs.median_time()\n",
    "    \n",
    "    return s1_median\n",
    "\n",
    "print('Function defined for SAR flood analysis processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all time periods\n",
    "print('Starting flood impact data processing...')\n",
    "print('Note: This process may take 10-15 minutes depending on data availability')\n",
    "\n",
    "processed_data = {}\n",
    "\n",
    "# Process pre-flood data\n",
    "try:\n",
    "    print('\\n=== Processing Pre-flood Data ===')\n",
    "    pre_flood_data = load_and_process_sar_flood(conn, spatial_extent, pre_flood_period, 'Pre-flood')\n",
    "    processed_data['pre_flood'] = pre_flood_data\n",
    "    print('✓ Pre-flood data processed successfully')\n",
    "except Exception as e:\n",
    "    print(f'✗ Error processing pre-flood data: {str(e)}')\n",
    "    processed_data['pre_flood'] = None\n",
    "\n",
    "# Process post-flood data\n",
    "try:\n",
    "    print('\\n=== Processing Post-flood Data ===')\n",
    "    post_flood_data = load_and_process_sar_flood(conn, spatial_extent, post_flood_period, 'Post-flood')\n",
    "    processed_data['post_flood'] = post_flood_data\n",
    "    print('✓ Post-flood data processed successfully')\n",
    "except Exception as e:\n",
    "    print(f'✗ Error processing post-flood data: {str(e)}')\n",
    "    processed_data['post_flood'] = None\n",
    "\n",
    "# Process reference data\n",
    "try:\n",
    "    print('\\n=== Processing Reference Data ===')\n",
    "    reference_data = load_and_process_sar_flood(conn, spatial_extent, reference_period, 'Reference')\n",
    "    processed_data['reference'] = reference_data\n",
    "    print('✓ Reference data processed successfully')\n",
    "except Exception as e:\n",
    "    print(f'✗ Error processing reference data: {str(e)}')\n",
    "    processed_data['reference'] = None\n",
    "\n",
    "# Summary\n",
    "valid_datasets = sum(1 for data in processed_data.values() if data is not None)\n",
    "print(f'\\nProcessing complete: {valid_datasets}/3 datasets successfully processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download Processed Data\n",
    "\n",
    "Download the processed SAR data for all time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all processed datasets\n",
    "downloaded_files = {}\n",
    "\n",
    "print('Downloading processed flood analysis data...')\n",
    "\n",
    "for period_name, data in processed_data.items():\n",
    "    if data is not None:\n",
    "        filename = f'emilia_romagna_{period_name}_flood.nc'\n",
    "        try:\n",
    "            print(f'Downloading {filename}...')\n",
    "            data.download(filename)\n",
    "            downloaded_files[period_name] = filename\n",
    "            print(f'✓ Downloaded {filename}')\n",
    "        except Exception as e:\n",
    "            print(f'✗ Error downloading {filename}: {str(e)}')\n",
    "            downloaded_files[period_name] = None\n",
    "    else:\n",
    "        print(f'Skipping {period_name} - no data available')\n",
    "        downloaded_files[period_name] = None\n",
    "\n",
    "valid_downloads = sum(1 for file in downloaded_files.values() if file is not None)\n",
    "print(f'\\nDownload complete: {valid_downloads} files successfully downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Downloaded Data and Prepare for Analysis\n",
    "\n",
    "Load all downloaded NetCDF files and prepare them for flood impact analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all downloaded files\n",
    "datasets = {}\n",
    "\n",
    "for period_name, filename in downloaded_files.items():\n",
    "    if filename is not None:\n",
    "        try:\n",
    "            ds = xr.open_dataset(filename)\n",
    "            datasets[period_name] = ds\n",
    "            print(f'Loaded {filename} - Shape: {ds.dims}')\n",
    "        except Exception as e:\n",
    "            print(f'Error loading {filename}: {str(e)}')\n",
    "            datasets[period_name] = None\n",
    "    else:\n",
    "        datasets[period_name] = None\n",
    "\n",
    "valid_datasets = sum(1 for ds in datasets.values() if ds is not None)\n",
    "print(f'\\nLoaded {valid_datasets} datasets for flood analysis')\n",
    "\n",
    "if valid_datasets > 0:\n",
    "    # Get a sample dataset to check structure\n",
    "    sample_ds = next(ds for ds in datasets.values() if ds is not None)\n",
    "    print(f'Dataset dimensions: {sample_ds.dims}')\n",
    "    print(f'Available bands: {list(sample_ds.data_vars)}')\n",
    "    print(f'Spatial resolution: ~{abs(sample_ds.x.values[1] - sample_ds.x.values[0]):.6f}° per pixel')\n",
    "else:\n",
    "    print('No datasets available for analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Flood Detection and Change Analysis\n",
    "\n",
    "Perform flood detection by comparing pre-flood and post-flood SAR backscatter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect flood areas using SAR backscatter change\n",
    "def detect_flood_areas(pre_flood_ds, post_flood_ds, vv_threshold=-3.0, vh_threshold=-2.0):\n",
    "    '''\n",
    "    Detect flood areas by comparing pre- and post-flood SAR data\n",
    "    \n",
    "    Parameters:\n",
    "    - pre_flood_ds: Pre-flood dataset\n",
    "    - post_flood_ds: Post-flood dataset\n",
    "    - vv_threshold: VV backscatter decrease threshold (dB) for flood detection\n",
    "    - vh_threshold: VH backscatter decrease threshold (dB) for flood detection\n",
    "    \n",
    "    Returns:\n",
    "    - flood_mask: Boolean array indicating flood areas\n",
    "    - change_vv: VV backscatter change (post - pre)\n",
    "    - change_vh: VH backscatter change (post - pre)\n",
    "    '''\n",
    "    \n",
    "    # Calculate backscatter changes\n",
    "    change_vv = post_flood_ds.VV.values - pre_flood_ds.VV.values\n",
    "    change_vh = post_flood_ds.VH.values - pre_flood_ds.VH.values\n",
    "    \n",
    "    # Detect flood areas (significant decrease in backscatter)\n",
    "    # Water appears dark in SAR due to specular reflection\n",
    "    flood_mask_vv = change_vv < vv_threshold\n",
    "    flood_mask_vh = change_vh < vh_threshold\n",
    "    \n",
    "    # Combined flood mask (either VV or VH indicates flooding)\n",
    "    flood_mask = flood_mask_vv | flood_mask_vh\n",
    "    \n",
    "    return flood_mask, change_vv, change_vh, flood_mask_vv, flood_mask_vh\n",
    "\n",
    "# Perform flood detection if we have both pre- and post-flood data\n",
    "if datasets['pre_flood'] is not None and datasets['post_flood'] is not None:\n",
    "    print('Performing flood detection analysis...')\n",
    "    \n",
    "    # Detect flood areas\n",
    "    flood_mask, change_vv, change_vh, flood_mask_vv, flood_mask_vh = detect_flood_areas(\n",
    "        datasets['pre_flood'], \n",
    "        datasets['post_flood'],\n",
    "        vv_threshold=-3.0,  # 3 dB decrease threshold for VV\n",
    "        vh_threshold=-2.0   # 2 dB decrease threshold for VH\n",
    "    )\n",
    "    \n",
    "    # Calculate flood statistics\n",
    "    total_pixels = flood_mask.size\n",
    "    flood_pixels = np.sum(flood_mask)\n",
    "    flood_percentage = (flood_pixels / total_pixels) * 100\n",
    "    \n",
    "    print(f'Flood detection completed:')\n",
    "    print(f'  Total pixels: {total_pixels:,}')\n",
    "    print(f'  Flood-affected pixels: {flood_pixels:,}')\n",
    "    print(f'  Flood coverage: {flood_percentage:.2f}% of analyzed area')\n",
    "    \n",
    "    # Estimate flood area (rough calculation)\n",
    "    pixel_size_deg = abs(datasets['pre_flood'].x.values[1] - datasets['pre_flood'].x.values[0])\n",
    "    pixel_area_km2 = (pixel_size_deg * 111) * (pixel_size_deg * 85)  # Rough conversion to km²\n",
    "    flood_area_km2 = flood_pixels * pixel_area_km2\n",
    "    \n",
    "    print(f'  Estimated flood area: {flood_area_km2:.1f} km²')\n",
    "    \n",
    "    # Change statistics\n",
    "    print(f'\\nBackscatter change statistics:')\n",
    "    print(f'  VV change range: {np.nanmin(change_vv):.2f} to {np.nanmax(change_vv):.2f} dB')\n",
    "    print(f'  VH change range: {np.nanmin(change_vh):.2f} to {np.nanmax(change_vh):.2f} dB')\n",
    "    print(f'  Mean VV change: {np.nanmean(change_vv):.2f} dB')\n",
    "    print(f'  Mean VH change: {np.nanmean(change_vh):.2f} dB')\n",
    "    \n",
    "else:\n",
    "    print('Cannot perform flood detection - missing pre-flood or post-flood data')\n",
    "    flood_mask = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization of Flood Impact\n",
    "\n",
    "Create comprehensive visualizations showing the flood impact and SAR backscatter changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize pre-flood and post-flood SAR images\n",
    "if datasets['pre_flood'] is not None and datasets['post_flood'] is not None:\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # Pre-flood VV\n",
    "    im1 = axes[0, 0].imshow(datasets['pre_flood'].VV.values, cmap='gray', vmin=-25, vmax=-5)\n",
    "    axes[0, 0].set_title('Pre-flood VV Backscatter\\n(May 1-15, 2023)')\n",
    "    axes[0, 0].axis('off')\n",
    "    cbar1 = plt.colorbar(im1, ax=axes[0, 0], label='Backscatter (dB)')\n",
    "    \n",
    "    # Post-flood VV\n",
    "    im2 = axes[0, 1].imshow(datasets['post_flood'].VV.values, cmap='gray', vmin=-25, vmax=-5)\n",
    "    axes[0, 1].set_title('Post-flood VV Backscatter\\n(May 17-31, 2023)')\n",
    "    axes[0, 1].axis('off')\n",
    "    cbar2 = plt.colorbar(im2, ax=axes[0, 1], label='Backscatter (dB)')\n",
    "    \n",
    "    # VV Change\n",
    "    im3 = axes[0, 2].imshow(change_vv, cmap='RdBu_r', vmin=-8, vmax=8)\n",
    "    axes[0, 2].set_title('VV Backscatter Change\\n(Post - Pre)')\n",
    "    axes[0, 2].axis('off')\n",
    "    cbar3 = plt.colorbar(im3, ax=axes[0, 2], label='Change (dB)')\n",
    "    \n",
    "    # Pre-flood VH\n",
    "    im4 = axes[1, 0].imshow(datasets['pre_flood'].VH.values, cmap='gray', vmin=-30, vmax=-10)\n",
    "    axes[1, 0].set_title('Pre-flood VH Backscatter\\n(May 1-15, 2023)')\n",
    "    axes[1, 0].axis('off')\n",
    "    cbar4 = plt.colorbar(im4, ax=axes[1, 0], label='Backscatter (dB)')\n",
    "    \n",
    "    # Post-flood VH\n",
    "    im5 = axes[1, 1].imshow(datasets['post_flood'].VH.values, cmap='gray', vmin=-30, vmax=-10)\n",
    "    axes[1, 1].set_title('Post-flood VH Backscatter\\n(May 17-31, 2023)')\n",
    "    axes[1, 1].axis('off')\n",
    "    cbar5 = plt.colorbar(im5, ax=axes[1, 1], label='Backscatter (dB)')\n",
    "    \n",
    "    # VH Change\n",
    "    im6 = axes[1, 2].imshow(change_vh, cmap='RdBu_r', vmin=-8, vmax=8)\n",
    "    axes[1, 2].set_title('VH Backscatter Change\\n(Post - Pre)')\n",
    "    axes[1, 2].axis('off')\n",
    "    cbar6 = plt.colorbar(im6, ax=axes[1, 2], label='Change (dB)')\n",
    "    \n",
    "    plt.suptitle('Emilia Romagna Flood Analysis - SAR Backscatter Comparison', fontsize=16, y=0.95)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\nInterpretation:')\n",
    "    print('- Dark areas in SAR images indicate low backscatter (water, smooth surfaces)')\n",
    "    print('- Bright areas indicate high backscatter (buildings, rough surfaces)')\n",
    "    print('- Blue areas in change maps show backscatter decrease (potential flooding)')\n",
    "    print('- Red areas in change maps show backscatter increase')\n",
    "    \n",
    "else:\n",
    "    print('Cannot create SAR comparison plots - missing data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize flood detection results\n",
    "if flood_mask is not None:\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Combined flood mask\n",
    "    im1 = axes[0, 0].imshow(flood_mask, cmap='Blues', alpha=0.8)\n",
    "    axes[0, 0].set_title('Detected Flood Areas\\n(Combined VV + VH)')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # VV flood mask\n",
    "    im2 = axes[0, 1].imshow(flood_mask_vv, cmap='Reds', alpha=0.8)\n",
    "    axes[0, 1].set_title('VV-based Flood Detection\\n(Threshold: -3 dB)')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # VH flood mask\n",
    "    im3 = axes[1, 0].imshow(flood_mask_vh, cmap='Greens', alpha=0.8)\n",
    "    axes[1, 0].set_title('VH-based Flood Detection\\n(Threshold: -2 dB)')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Flood overlay on post-flood VV\n",
    "    axes[1, 1].imshow(datasets['post_flood'].VV.values, cmap='gray', vmin=-25, vmax=-5)\n",
    "    axes[1, 1].imshow(flood_mask, cmap='Blues', alpha=0.6)\n",
    "    axes[1, 1].set_title('Flood Areas Overlay\\n(Blue = Detected Floods)')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.suptitle('Flood Detection Results - May 2023 Emilia Romagna Floods', fontsize=16, y=0.95)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a summary statistics plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Histogram of VV changes\n",
    "    axes[0].hist(change_vv.flatten(), bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[0].axvline(-3, color='red', linestyle='--', linewidth=2, label='Flood threshold (-3 dB)')\n",
    "    axes[0].set_xlabel('VV Backscatter Change (dB)')\n",
    "    axes[0].set_ylabel('Number of Pixels')\n",
    "    axes[0].set_title('Distribution of VV Backscatter Changes')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Histogram of VH changes\n",
    "    axes[1].hist(change_vh.flatten(), bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "    axes[1].axvline(-2, color='red', linestyle='--', linewidth=2, label='Flood threshold (-2 dB)')\n",
    "    axes[1].set_xlabel('VH Backscatter Change (dB)')\n",
    "    axes[1].set_ylabel('Number of Pixels')\n",
    "    axes[1].set_title('Distribution of VH Backscatter Changes')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print('Cannot create flood detection plots - no flood mask available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparison with Reference Period\n",
    "\n",
    "Compare the flood period with the same time in the previous year to assess the anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with reference period if available\n",
    "if datasets['reference'] is not None and datasets['post_flood'] is not None:\n",
    "    \n",
    "    print('Comparing flood period with reference year...')\n",
    "    \n",
    "    # Calculate changes relative to reference period\n",
    "    ref_change_vv = datasets['post_flood'].VV.values - datasets['reference'].VV.values\n",
    "    ref_change_vh = datasets['post_flood'].VH.values - datasets['reference'].VH.values\n",
    "    \n",
    "    # Detect anomalous areas (much different from reference year)\n",
    "    anomaly_threshold = 4.0  # 4 dB difference from reference\n",
    "    anomaly_mask_vv = np.abs(ref_change_vv) > anomaly_threshold\n",
    "    anomaly_mask_vh = np.abs(ref_change_vh) > anomaly_threshold\n",
    "    anomaly_mask = anomaly_mask_vv | anomaly_mask_vh\n",
    "    \n",
    "    # Statistics\n",
    "    anomaly_pixels = np.sum(anomaly_mask)\n",
    "    anomaly_percentage = (anomaly_pixels / anomaly_mask.size) * 100\n",
    "    \n",
    "    print(f'Anomaly detection (vs. reference year):')\n",
    "    print(f'  Anomalous pixels: {anomaly_pixels:,}')\n",
    "    print(f'  Anomaly coverage: {anomaly_percentage:.2f}% of analyzed area')\n",
    "    \n",
    "    # Visualize reference comparison\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Reference year VV\n",
    "    im1 = axes[0, 0].imshow(datasets['reference'].VV.values, cmap='gray', vmin=-25, vmax=-5)\n",
    "    axes[0, 0].set_title('Reference VV Backscatter\\n(May 2022)')\n",
    "    axes[0, 0].axis('off')\n",
    "    cbar1 = plt.colorbar(im1, ax=axes[0, 0], label='Backscatter (dB)')\n",
    "    \n",
    "    # 2023 vs 2022 VV change\n",
    "    im2 = axes[0, 1].imshow(ref_change_vv, cmap='RdBu_r', vmin=-10, vmax=10)\n",
    "    axes[0, 1].set_title('VV Change vs Reference\\n(2023 - 2022)')\n",
    "    axes[0, 1].axis('off')\n",
    "    cbar2 = plt.colorbar(im2, ax=axes[0, 1], label='Change (dB)')\n",
    "    \n",
    "    # Reference year VH\n",
    "    im3 = axes[1, 0].imshow(datasets['reference'].VH.values, cmap='gray', vmin=-30, vmax=-10)\n",
    "    axes[1, 0].set_title('Reference VH Backscatter\\n(May 2022)')\n",
    "    axes[1, 0].axis('off')\n",
    "    cbar3 = plt.colorbar(im3, ax=axes[1, 0], label='Backscatter (dB)')\n",
    "    \n",
    "    # 2023 vs 2022 VH change\n",
    "    im4 = axes[1, 1].imshow(ref_change_vh, cmap='RdBu_r', vmin=-10, vmax=10)\n",
    "    axes[1, 1].set_title('VH Change vs Reference\\n(2023 - 2022)')\n",
    "    axes[1, 1].axis('off')\n",
    "    cbar4 = plt.colorbar(im4, ax=axes[1, 1], label='Change (dB)')\n",
    "    \n",
    "    plt.suptitle('Comparison with Reference Year (2022)', fontsize=16, y=0.95)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show anomaly detection\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Anomaly mask\n",
    "    im1 = axes[0].imshow(anomaly_mask, cmap='Reds', alpha=0.8)\n",
    "    axes[0].set_title('Anomalous Areas\\n(>4 dB difference from 2022)')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Combined flood and anomaly\n",
    "    if flood_mask is not None:\n",
    "        axes[1].imshow(datasets['post_flood'].VV.values, cmap='gray', vmin=-25, vmax=-5)\n",
    "        axes[1].imshow(flood_mask, cmap='Blues', alpha=0.5, label='Flood areas')\n",
    "        axes[1].imshow(anomaly_mask, cmap='Reds', alpha=0.3, label='Anomalous areas')\n",
    "        axes[1].set_title('Flood + Anomaly Overlay\\n(Blue=Flood, Red=Anomaly)')\n",
    "    else:\n",
    "        axes[1].imshow(anomaly_mask, cmap='Reds', alpha=0.8)\n",
    "        axes[1].set_title('Anomalous Areas Only')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print('Cannot perform reference comparison - missing reference or post-flood data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Impact Assessment\n",
    "\n",
    "Provide a comprehensive summary of the flood impact analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive flood impact summary\n",
    "print('=' * 60)\n",
    "print('EMILIA ROMAGNA FLOOD IMPACT ASSESSMENT SUMMARY')\n",
    "print('=' * 60)\n",
    "\n",
    "print('ANALYSIS DETAILS:')\n",
    "print(f'  Study area: Emilia Romagna, Italy ({spatial_extent})')\n",
    "print(f'  Flood event: May 16-17, 2023')\n",
    "print(f'  Analysis method: Sentinel-1 SAR change detection')\n",
    "print(f'  Data source: Copernicus Dataspace via openEO')\n",
    "\n",
    "if flood_mask is not None:\n",
    "    print('FLOOD DETECTION RESULTS:')\n",
    "    print(f'  Total analyzed area: ~{lat_range*111:.0f} × {lon_range*85:.0f} km')\n",
    "    print(f'  Flood-affected pixels: {flood_pixels:,} ({flood_percentage:.2f}%)')\n",
    "    print(f'  Estimated flood area: {flood_area_km2:.1f} km²')\n",
    "    \n",
    "    print('BACKSCATTER CHANGE ANALYSIS:')\n",
    "    print(f'  VV polarization:')\n",
    "    print(f'    - Mean change: {np.nanmean(change_vv):.2f} dB')\n",
    "    print(f'    - Change range: {np.nanmin(change_vv):.2f} to {np.nanmax(change_vv):.2f} dB')\n",
    "    print(f'    - Pixels below -3 dB threshold: {np.sum(change_vv < -3):,}')\n",
    "    print(f'  VH polarization:')\n",
    "    print(f'    - Mean change: {np.nanmean(change_vh):.2f} dB')\n",
    "    print(f'    - Change range: {np.nanmin(change_vh):.2f} to {np.nanmax(change_vh):.2f} dB')\n",
    "    print(f'    - Pixels below -2 dB threshold: {np.sum(change_vh < -2):,}')\n",
    "\n",
    "if 'reference' in datasets and datasets['reference'] is not None and datasets['post_flood'] is not None:\n",
    "    print('COMPARISON WITH REFERENCE YEAR (2022):')\n",
    "    print(f'  Anomalous pixels (>4 dB difference): {anomaly_pixels:,} ({anomaly_percentage:.2f}%)')\n",
    "    print(f'  This indicates areas significantly different from normal conditions')\n",
    "\n",
    "print('KEY FINDINGS:')\n",
    "print('1. SAR-based flood detection successfully identified water-covered areas')\n",
    "print('2. Significant backscatter decreases indicate specular reflection from water')\n",
    "print('3. VV polarization is more sensitive to open water detection')\n",
    "print('4. VH polarization helps identify flooded vegetation areas')\n",
    "\n",
    "print('METHODOLOGY ADVANTAGES:')\n",
    "print('- Weather-independent monitoring (SAR penetrates clouds)')\n",
    "print('- Rapid assessment capability for emergency response')\n",
    "print('- Quantitative change detection with statistical thresholds')\n",
    "print('- Historical comparison for anomaly detection')\n",
    "\n",
    "print('APPLICATIONS:')\n",
    "print('- Emergency response and damage assessment')\n",
    "print('- Insurance claim validation')\n",
    "print('- Flood risk mapping and management')\n",
    "print('- Climate change impact studies')\n",
    "print('- Infrastructure vulnerability assessment')\n",
    "\n",
    "print('LIMITATIONS:')\n",
    "print('- Urban areas may show complex scattering patterns')\n",
    "print('- Vegetation can mask underlying flood conditions')\n",
    "print('- Temporal resolution limited by satellite revisit time')\n",
    "print('- Threshold selection affects detection sensitivity')\n",
    "\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up downloaded files (optional)\n",
    "import os\n",
    "\n",
    "print('\\n=== FILE MANAGEMENT ===')\n",
    "print('Downloaded files:')\n",
    "total_size = 0\n",
    "for period_name, filename in downloaded_files.items():\n",
    "    if filename and os.path.exists(filename):\n",
    "        file_size = os.path.getsize(filename) / (1024*1024)  # MB\n",
    "        total_size += file_size\n",
    "        print(f'  {filename} ({file_size:.1f} MB)')\n",
    "\n",
    "print(f'Total data downloaded: {total_size:.1f} MB')\n",
    "\n",
    "# Uncomment the following lines to remove downloaded files\n",
    "# print('Cleaning up downloaded files...')\n",
    "# for period_name, filename in downloaded_files.items():\n",
    "#     if filename and os.path.exists(filename):\n",
    "#         os.remove(filename)\n",
    "#         print(f'Removed {filename}')\n",
    "# print('Cleanup completed')\n",
    "\n",
    "print('\\nFlood impact assessment analysis completed successfully!')\n",
    "print('\\nFor more detailed analysis, consider:')\n",
    "print('- Integrating with optical imagery for validation')\n",
    "print('- Using higher resolution SAR data (e.g., TerraSAR-X)')\n",
    "print('- Incorporating topographic data for flood modeling')\n",
    "print('- Analyzing multiple flood events for pattern recognition')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}